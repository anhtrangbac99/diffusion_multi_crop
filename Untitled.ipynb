{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "521dffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as TF\n",
    "import torchvision.datasets as dsets\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "# import matplotlib.pyplot as plt\n",
    "import utils\n",
    "from guided_diffusion.unet import UNetModel\n",
    "import math\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import json\n",
    "from collections import namedtuple\n",
    "import argparse\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "from blur_diffusion import Deblurring, ForwardBlurIncreasing, gaussian_kernel_1d\n",
    "from utils import normalize_np, clear\n",
    "from EMA import EMA\n",
    "from torch.nn import DataParallel\n",
    "from fid import FID\n",
    "from scipy.integrate import solve_ivp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e660bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Configs')\n",
    "parser.add_argument('--gpu', default='0',type=str, help='gpu num')\n",
    "parser.add_argument('--dataset',default='cifar10', type=str, help='cifar10 / mnist')\n",
    "parser.add_argument('--name', default='blur_diff',type=str, help='Saving directory name')\n",
    "parser.add_argument('--ckpt', default='', type=str, help='UNet checkpoint')\n",
    "\n",
    "parser.add_argument('--bsize', default=16, type=int, help='batchsize')\n",
    "parser.add_argument('--N', default=500, type=int, help='Max diffusion timesteps')\n",
    "parser.add_argument('--sig', default=0.4, type=float, help='sigma value for blur kernel')\n",
    "parser.add_argument('--sig_min', default=0, type=float, help='sigma value for blur kernel')\n",
    "parser.add_argument('--sig_max', default=0.1, type=float, help='sigma value for blur kernel')\n",
    "parser.add_argument('--lr', default=0.00005, type=float, help='learning rate')\n",
    "parser.add_argument('--noise_schedule', default='linear', type=str, help='Type of noise schedule to use')\n",
    "parser.add_argument('--betamin', default=0.0001, type=float, help='beta (min). get_score(1) can diverge if this is too low.')\n",
    "parser.add_argument('--betamax', default=0.02, type=float, help='beta (max)')\n",
    "parser.add_argument('--fromprior', default=True, type=bool, help='start sampling from prior')\n",
    "parser.add_argument('--gtscore', action='store_true', help='Use ground truth score for reverse diffusion')\n",
    "parser.add_argument('--max_iter', default=15000, type=int, help='max iterations')\n",
    "parser.add_argument('--eval_iter', default=1000, type=int, help='eval iterations')\n",
    "parser.add_argument('--fid_iter', default=2000, type=int, help='eval iterations')\n",
    "parser.add_argument('--fid_num_samples', default=100, type=int, help='eval iterations')\n",
    "parser.add_argument('--fid_bsize', default=32, type=int, help='eval iterations')\n",
    "parser.add_argument('--loss_type', type=str, default = 'eps_simple', choices=['sm_simple', 'eps_simple', 'sm_exact', 'std_matching'])\n",
    "parser.add_argument('--f_type', type=str, default = 'linear', choices=['linear', 'log', 'quadratic', 'cubic', 'quartic', 'triangular'])\n",
    "parser.add_argument('--dropout', default=0, type=float, help='dropout')\n",
    "\n",
    "# EMA, save\n",
    "parser.add_argument('--use_ema', action='store_true',\n",
    "                    help='use EMA or not')\n",
    "parser.add_argument('--inference', action='store_true')\n",
    "parser.add_argument('--freq_feat', action='store_true', help = \"concat Utx_i\")\n",
    "parser.add_argument('--ode', action='store_true', help = \"ODE fast sampler\")\n",
    "parser.add_argument('--ema_decay', type=float, default=0.9999, help='decay rate for EMA')\n",
    "parser.add_argument('--save_every', type=int, default=50000, help='How often we wish to save ckpts')\n",
    "opt = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e20377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 1000\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(f'cuda:{opt.gpu}')\n",
    "device = torch.device('cuda')\n",
    "print(\"N:\", opt.N)\n",
    "N = opt.N\n",
    "bsize = opt.bsize\n",
    "beta_min = opt.betamin\n",
    "beta_max = opt.betamax\n",
    "sig = opt.sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae3ab4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer =  transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.5), \n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9124416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='.', train=True, transform=train_transformer, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='.', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8f7f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=opt.bsize,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=opt.bsize,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d71d3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('experiments','train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b6fc182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: experiments\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [01:21<00:00, 38.50it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m fid_eval \u001b[38;5;241m=\u001b[39m FID(real_dir \u001b[38;5;241m=\u001b[39mtrain_dir, device \u001b[38;5;241m=\u001b[39m device,bsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m resolution \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_train\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      3\u001b[0m input_nc \u001b[38;5;241m=\u001b[39m dataset_train[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m ksize \u001b[38;5;241m=\u001b[39m resolution \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_train' is not defined"
     ]
    }
   ],
   "source": [
    "fid_eval = FID(real_dir =train_dir, device = device,bsize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bea7bc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains zero? tensor(False, device='cuda:0')\n",
      "blur.U_small.shape: torch.Size([32, 32])\n",
      "fs:  tensor([-6.2563e-05,  0.0000e+00,  6.2563e-05,  ...,  6.2375e-02,\n",
      "         6.2437e-02,  6.2500e-02], device='cuda:0')\n",
      "p:  torch.Size([1001, 3072])\n",
      "D:  torch.Size([1001, 3072])\n"
     ]
    }
   ],
   "source": [
    "resolution = train_dataset[0][0].shape[-1]\n",
    "input_nc = train_dataset[0][0].shape[0]\n",
    "ksize = resolution * 2 - 1\n",
    "pad = 0\n",
    "\n",
    "# define forward blur\n",
    "kernel = gaussian_kernel_1d(ksize, sig)\n",
    "blur = Deblurring(kernel, input_nc, resolution, device=device)\n",
    "print(\"blur.U_small.shape:\", blur.U_small.shape)\n",
    "D_diag = blur.singulars()\n",
    "fb = ForwardBlurIncreasing(N=N, beta_min=beta_min, beta_max=beta_max, sig=sig, sig_max = opt.sig_max, sig_min = opt.sig_min, D_diag=D_diag,\n",
    "                    blur=blur, channel=input_nc, device=device, noise_schedule=opt.noise_schedule, resolution=resolution, pad=pad, f_type=opt.f_type)\n",
    "dir = os.path.join('experiments', opt.name)\n",
    "writer = SummaryWriter(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d600cb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_blocks torch.Size([128, 3, 3, 3])\n",
      "input_nc 3 resolution 32\n",
      "MAE = 3.758759703487158e-06\n",
      "x_100.std() = 0.49324896931648254\n",
      "x_100.mean() = 0.4726855754852295\n",
      "x_200.std() = 0.7742474675178528\n",
      "x_200.mean() = 0.403974711894989\n",
      "x_300.std() = 0.9143067598342896\n",
      "x_300.mean() = 0.321166455745697\n",
      "x_400.std() = 0.9757927656173706\n",
      "x_400.mean() = 0.2228381335735321\n",
      "x_500.std() = 0.9767712354660034\n",
      "x_500.mean() = 0.1384417861700058\n",
      "x_600.std() = 0.9953518509864807\n",
      "x_600.mean() = 0.05848237872123718\n",
      "x_700.std() = 0.9877786636352539\n",
      "x_700.mean() = 0.01588168740272522\n",
      "x_800.std() = 0.9873171448707581\n",
      "x_800.mean() = 0.025635406374931335\n",
      "x_900.std() = 1.009985089302063\n",
      "x_900.mean() = 0.021165339276194572\n",
      "x_1000.std() = 1.010701298713684\n",
      "x_1000.mean() = 0.039750274270772934\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = UNetModel(resolution, input_nc, 128, input_nc, blur = blur, dropout=opt.dropout, freq_feat = opt.freq_feat)\n",
    "if not opt.ckpt == '' and os.path.exists(opt.ckpt):\n",
    "    model.load_state_dict(torch.load(opt.ckpt))\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "print(\"input_nc\", input_nc, \"resolution\", resolution)\n",
    "\n",
    "# data_loader = torch.utils.data.DataLoader(dataset=dataset_train,\n",
    "#                                           batch_size=bsize,\n",
    "#                                           shuffle=True,\n",
    "#                                           drop_last=True)\n",
    "# data_loader_test = torch.utils.data.DataLoader(dataset=dataset_test,\n",
    "#                                                batch_size=bsize,\n",
    "#                                                shuffle=False,\n",
    "#                                                drop_last=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=opt.lr)\n",
    "if opt.use_ema:\n",
    "    optimizer = EMA(optimizer, ema_decay=opt.ema_decay)\n",
    "\n",
    "# forward process visualization\n",
    "sample = train_dataset[1][0].unsqueeze(0)\n",
    "\n",
    "x_0 = sample[:4]\n",
    "x_0 = x_0.to(device)\n",
    "i = np.array([500] * x_0.shape[0])\n",
    "i = torch.from_numpy(i).to(device)\n",
    "fb.sanity(x_0, i)\n",
    "\n",
    "sample_list = []\n",
    "for i in range(0, N+1, N//10):\n",
    "    if i == 0:\n",
    "        sample_list.append(x_0[0])\n",
    "        continue\n",
    "    i = np.array([i] * x_0.shape[0])\n",
    "    i = torch.from_numpy(i).to(device)\n",
    "    x_i = fb.get_x_i(x_0, i)\n",
    "    sample_list.append(x_i[0])\n",
    "    print(f\"x_{i.item()}.std() = {x_i.std()}\")\n",
    "    print(f\"x_{i.item()}.mean() = {x_i.mean()}\")\n",
    "\n",
    "\n",
    "grid_sample = torch.cat(sample_list, dim=2)\n",
    "utils.tensor_imsave(grid_sample, \"./\" + dir, \"forward_process.jpg\")\n",
    "with open(os.path.join(dir, \"config.json\"), \"w\") as json_file:\n",
    "    json.dump(vars(opt), json_file)\n",
    "import time\n",
    "meta_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f395a70",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 4.00 GiB total capacity; 3.37 GiB already allocated; 0 bytes free; 3.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_train\u001b[39m\u001b[38;5;124m'\u001b[39m, loss, step)\n\u001b[0;32m     28\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 29\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\science\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\science\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\science\\lib\\site-packages\\torch\\optim\\adam.py:132\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    129\u001b[0m     state_steps \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     adam(\n\u001b[0;32m    142\u001b[0m         params_with_grad,\n\u001b[0;32m    143\u001b[0m         grads,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\science\\lib\\site-packages\\torch\\optim\\adam.py:94\u001b[0m, in \u001b[0;36mAdam._init_group\u001b[1;34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[0;32m     92\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp_avg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# Maintains max of all exp. moving avg. of sq. grad. values\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 4.00 GiB total capacity; 3.37 GiB already allocated; 0 bytes free; 3.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for step in range(opt.max_iter):\n",
    "    if not opt.inference:\n",
    "        elips = time.time()\n",
    "        try:\n",
    "            x_0, _ = train_iter.next()\n",
    "        except:\n",
    "            train_iter = iter(train_loader)\n",
    "            image, _ = next(train_iter)\n",
    "        \"\"\"\n",
    "        training\n",
    "        \"\"\"\n",
    "        assert x_0.shape[-1] == resolution, f\"{x_0.shape}\"\n",
    "        i = np.random.uniform(1 / N, 1, size = (x_0.shape[0])) * N\n",
    "        i = torch.from_numpy(i).to(device).type(torch.long)\n",
    "\n",
    "        x_0 = x_0.to(device)\n",
    "        x_i, eps = fb.get_x_i(x_0, i, return_eps = True)\n",
    "\n",
    "        if opt.loss_type == \"sm_simple\":\n",
    "            loss = fb.get_loss_i_simple(model, x_0, x_i, i)\n",
    "        elif opt.loss_type == \"eps_simple\":\n",
    "            loss = fb.get_loss_i_eps_simple(model, x_i, i, eps)\n",
    "        elif opt.loss_type == \"sm_exact\":\n",
    "            loss = fb.get_loss_i_exact(model, x_0, x_i, i)\n",
    "        elif opt.loss_type == \"std_matching\":\n",
    "            loss = fb.get_loss_i_std_matching(model, x_i, i, eps)\n",
    "        writer.add_scalar('loss_train', loss, step)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if step % 100 == 0:\n",
    "            print(step, loss)\n",
    "        # print(f\"time: {time.time() - elips}\")\n",
    "    # Calcuate FID\n",
    "    if step > 240001:\n",
    "        fid_iter = opt.fid_iter\n",
    "    else:\n",
    "        fid_iter = 240000\n",
    "    if (step % fid_iter == 0 and step > 0):\n",
    "        id = 0\n",
    "        if not os.path.exists(os.path.join(\"./\",dir, f\"{step}\")):\n",
    "            os.mkdir(os.path.join(\"./\",dir, f\"{step}\"))\n",
    "        with torch.no_grad():\n",
    "            if opt.use_ema:\n",
    "                optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "            model = model.eval()\n",
    "            for _ in range(opt.fid_num_samples // opt.fid_bsize):\n",
    "                i = np.array([opt.N - 1] * opt.fid_bsize)\n",
    "                i = torch.from_numpy(i).to(device)\n",
    "                pred = fb.get_x_N([opt.fid_bsize, input_nc, resolution, resolution], i)\n",
    "                for i in reversed(range(1, opt.N)):\n",
    "                    i = np.array([i] * opt.fid_bsize)\n",
    "                    i = torch.from_numpy(i).to(device)\n",
    "                    if opt.loss_type == \"sm_simple\":\n",
    "                        s = model(pred, i)\n",
    "                    elif opt.loss_type == \"eps_simple\":\n",
    "                        eps = model(pred, i)\n",
    "                        s = fb.get_score_from_eps(eps, i)\n",
    "                    elif opt.loss_type == \"sm_exact\":\n",
    "                        s = model(pred, i)\n",
    "                    elif opt.loss_type == \"std_matching\":\n",
    "                        std = model(pred, i)\n",
    "                        s = fb.get_score_from_std(std, i)\n",
    "                    else:\n",
    "                        raise NotImplementedError\n",
    "                    s = fb.U_I_minus_B_Ut(s, i)\n",
    "                    rms = lambda x: torch.sqrt(torch.mean(x ** 2))\n",
    "                    # print(f\"rms(s) * fb._beta_i(i) = {rms(s) * fb._beta_i(i)[0]}\")\n",
    "                    hf = pred - fb.W(pred, i)\n",
    "                    # Anderson theorem\n",
    "                    pred1 = pred + hf # unsharpening mask filtering\n",
    "                    pred2 = pred1 + s  # # denoising\n",
    "                    if i[0] > 2:\n",
    "                        pred = pred2 + fb.U_I_minus_B_sqrt_Ut(torch.randn_like(pred), i) # inject noise\n",
    "                    else:\n",
    "                        pred = pred2\n",
    "                    # print(f\"i = {i[0]}, rmse = {torch.sqrt(torch.mean(pred**2))}, mean = {torch.mean(pred)} std = {torch.std(pred)}\" )\n",
    "                for sample in pred:\n",
    "                    save_image(sample, os.path.join(dir, f\"{step}\", f\"{id:05d}.png\"))\n",
    "                    id += 1\n",
    "        if opt.use_ema:\n",
    "            optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "            model = model.train()\n",
    "        fid = fid_eval(os.path.join(dir, f\"{step}\"))\n",
    "        writer.add_scalar('fid', fid, step)\n",
    "        print(f\"step {step}, fid = {fid}\")\n",
    "    if (step % opt.eval_iter == 0 and step > 0) or opt.inference:\n",
    "        \"\"\"\n",
    "        sampling (eval)\n",
    "        \"\"\"\n",
    "        cnt = 0\n",
    "        loss = 0\n",
    "        \n",
    "\n",
    "        with torch.no_grad():\n",
    "            if opt.use_ema:\n",
    "                optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "            model = model.eval()\n",
    "\n",
    "            if opt.ode:\n",
    "                raise NotImplementedError\n",
    "                def to_flattened_numpy(x):\n",
    "                    \"\"\"Flatten a torch tensor `x` and convert it to numpy.\"\"\"\n",
    "                    return x.detach().cpu().numpy().reshape((-1,))\n",
    "                def from_flattened_numpy(x, shape):\n",
    "                    \"\"\"Form a torch tensor with the given `shape` from a flattened numpy array `x`.\"\"\"\n",
    "                    return torch.from_numpy(x.reshape(shape))\n",
    "                def ode_func(i, y):\n",
    "                    i = int(i*N)\n",
    "                    print(f\"i = {i}\")\n",
    "                    y = from_flattened_numpy(y, [bsize, input_nc, resolution, resolution]).to(device).type(torch.float32)\n",
    "                    i = np.array([N - 1] * bsize)\n",
    "                    i = torch.from_numpy(i).to(device)\n",
    "                    if opt.loss_type == \"sm_simple\":\n",
    "                            s = model(y, i)\n",
    "                    elif opt.loss_type == \"eps_simple\":\n",
    "                        eps = model(y, i)\n",
    "                        s = fb.get_score_from_eps(eps, i)\n",
    "                    elif opt.loss_type == \"sm_exact\":\n",
    "                        s = model(y, i)\n",
    "                    elif opt.loss_type == \"std_matching\":\n",
    "                        std = model(y, i)\n",
    "                        s = fb.get_score_from_std(std, i)\n",
    "                    else:\n",
    "                        raise NotImplementedError\n",
    "                    s = fb.U_I_minus_B_Ut(s, i)\n",
    "                    hf = y - fb.W(y, i)\n",
    "                    dt = - 1.0 / N\n",
    "                    drift = (s/2 + hf) / dt\n",
    "                    drift = to_flattened_numpy(drift)\n",
    "                    return drift\n",
    "                x_N = fb.get_x_N([bsize, input_nc, resolution, resolution], N)\n",
    "                solution = solve_ivp(ode_func, (1, 1e-3), to_flattened_numpy(x_N),\n",
    "                                     rtol=1e-3, atol=1e-3, method=\"RK45\")\n",
    "                nfe = solution.nfev\n",
    "                solution = torch.tensor(solution.y[:, -1]).reshape(x_N.shape).to(device).type(torch.float32)\n",
    "                \n",
    "                save_image(solution, \"./solution.jpg\")\n",
    "                print(f\"nfe = {nfe}\")\n",
    "                raise NotImplementedError\n",
    "            for x_0, _ in test_loader:\n",
    "                x_0 = x_0.to(device)\n",
    "                # for v in range(0, 250, 20):\n",
    "                #     x_0[:, :, v, :] = 0\n",
    "                if opt.fromprior:\n",
    "                    i = np.array([N - 1] * x_0.shape[0])\n",
    "                    i = torch.from_numpy(i).to(device)\n",
    "                    pred = fb.get_x_N(x_0.shape, i)\n",
    "                    print(f\"pred.std() = {pred.std()}\")\n",
    "                else:\n",
    "                    i = np.array([N-1] * x_0.shape[0])\n",
    "                    i = torch.from_numpy(i).to(device)\n",
    "                    pred = fb.get_x_i(x_0, i)\n",
    "                preds = [pred]\n",
    "\n",
    "                for i in reversed(range(1, N)):\n",
    "                    i = np.array([i] * x_0.shape[0])\n",
    "                    i = torch.from_numpy(i).to(device)\n",
    "                    if opt.gtscore:\n",
    "                        s = fb.get_score_gt(pred, x_0, i)\n",
    "                    else:\n",
    "                        if opt.loss_type == \"sm_simple\":\n",
    "                            s = model(pred, i)\n",
    "                        elif opt.loss_type == \"eps_simple\":\n",
    "                            eps = model(pred, i)\n",
    "                            s = fb.get_score_from_eps(eps, i)\n",
    "                        elif opt.loss_type == \"sm_exact\":\n",
    "                            s = model(pred, i)\n",
    "                        elif opt.loss_type == \"std_matching\":\n",
    "                            std = model(pred, i)\n",
    "                            s = fb.get_score_from_std(std, i)\n",
    "                        else:\n",
    "                            raise NotImplementedError\n",
    "                    s = fb.U_I_minus_B_Ut(s, i)\n",
    "                    rms = lambda x: torch.sqrt(torch.mean(x ** 2))\n",
    "                    # print(f\"rms(s) * fb._beta_i(i) = {rms(s) * fb._beta_i(i)[0]}\")\n",
    "                    hf = pred - fb.W(pred, i)\n",
    "                    # Anderson theorem\n",
    "                    pred1 = pred + hf # unsharpening mask filtering\n",
    "                    pred2 = pred1 + s  # # denoising\n",
    "                    if i[0] > 2:\n",
    "                        pred = pred2 + fb.U_I_minus_B_sqrt_Ut(torch.randn_like(pred), i) # inject noise\n",
    "                    else:\n",
    "                        pred = pred2\n",
    "                    # print(f\"i = {i[0]}, rmse = {torch.sqrt(torch.mean(pred**2))}, mean = {torch.mean(pred)} std = {torch.std(pred)}\")\n",
    "                    # assert rms(pred) < 100\n",
    "                    if (i[0]) % (N // 10) == 0:\n",
    "                        img = pred[0]\n",
    "                        preds.append(pred)\n",
    "\n",
    "                preds.append(pred)\n",
    "                assert x_0.shape == pred.shape\n",
    "                # visualize\n",
    "                grid = torch.cat(preds, dim=3) # grid_sample.shape: (bsize, channel, H, W * 12)\n",
    "                # (batch_size, channel, H, W * 12) -> (channel, H * bsize, W * 12)\n",
    "                grid = grid.permute(1, 0, 2, 3).contiguous().view(grid.shape[1], -1, grid.shape[3])\n",
    "                # (bsize, channel, H, W) -> (channel, H, W * bsize)\n",
    "                gt = x_0.permute(1, 2, 0, 3).contiguous().view(x_0.shape[1], -1, x_0.shape[3] * x_0.shape[0])\n",
    "                if cnt <= 2:\n",
    "                    utils.tensor_imsave(gt, \"./\" + dir, f\"{step}_{cnt}_GT.jpg\")\n",
    "                    utils.tensor_imsave(grid, \"./\" + dir, f\"{step}_{cnt}_pred.jpg\")\n",
    "              \n",
    "                cnt += 1\n",
    "                loss += TF.l1_loss(x_0, pred) / 2\n",
    "\n",
    "                if cnt == 2:\n",
    "                    break\n",
    "        print(f\"step: {step} loss: {loss}\")\n",
    "        writer.add_scalar('loss_val', loss, meta_iter)\n",
    "        f = open('./' + str(dir) + '/log.txt', 'a')\n",
    "\n",
    "        f.write(f\"Step: {step} loss: {loss}\" + '\\n')\n",
    "\n",
    "        f.close()\n",
    "        model.train()\n",
    "        if opt.use_ema:\n",
    "            optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "    if step % opt.save_every == 1:\n",
    "        if opt.use_ema:\n",
    "            optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            torch.save(model.module.state_dict(), os.path.join(dir, f\"model_{step}.ckpt\"))\n",
    "        else:\n",
    "            torch.save(model.state_dict(), os.path.join(dir, f\"model_{step}.ckpt\"))\n",
    "        if opt.use_ema:\n",
    "            optimizer.swap_parameters_with_ema(store_params_in_ema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa70436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3a1982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
