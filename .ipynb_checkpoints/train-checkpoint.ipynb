{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ebb44b7",
   "metadata": {},
   "source": [
    "# 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "521dffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as TF\n",
    "import torchvision.datasets as dsets\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "# import matplotlib.pyplot as plt\n",
    "import utils\n",
    "from guided_diffusion.unet import UNetModel\n",
    "import math\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import json\n",
    "from collections import namedtuple\n",
    "import argparse\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "from blur_diffusion import Deblurring, ForwardBlurIncreasing, gaussian_kernel_1d\n",
    "from utils import normalize_np, clear\n",
    "from EMA import EMA\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from fid import FID\n",
    "from scipy.integrate import solve_ivp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8278df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import ImageFilter\n",
    "import random\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e660bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Configs')\n",
    "parser.add_argument('--gpu', default='0',type=str, help='gpu num')\n",
    "parser.add_argument('--dataset',default='cifar10', type=str, help='cifar10 / mnist')\n",
    "parser.add_argument('--name', default='blur_diff',type=str, help='Saving directory name')\n",
    "parser.add_argument('--ckpt', default='', type=str, help='UNet checkpoint')\n",
    "parser.add_argument('--nodes', default=1,\n",
    "                    type=int, metavar='N')\n",
    "parser.add_argument('-g', default=1, type=int,\n",
    "                    help='number of gpus per node')\n",
    "parser.add_argument('-nr', '--nr', default=0, type=int,\n",
    "                    help='ranking within the nodes')\n",
    "parser.add_argument('--bsize', default=4, type=int, help='batchsize')\n",
    "parser.add_argument('--N', default=500, type=int, help='Max diffusion timesteps')\n",
    "parser.add_argument('--sig', default=0.4, type=float, help='sigma value for blur kernel')\n",
    "parser.add_argument('--sig_min', default=0, type=float, help='sigma value for blur kernel')\n",
    "parser.add_argument('--sig_max', default=0.1, type=float, help='sigma value for blur kernel')\n",
    "parser.add_argument('--lr', default=0.00005, type=float, help='learning rate')\n",
    "parser.add_argument('--noise_schedule', default='linear', type=str, help='Type of noise schedule to use')\n",
    "parser.add_argument('--betamin', default=0.0001, type=float, help='beta (min). get_score(1) can diverge if this is too low.')\n",
    "parser.add_argument('--betamax', default=0.02, type=float, help='beta (max)')\n",
    "parser.add_argument('--fromprior', default=True, type=bool, help='start sampling from prior')\n",
    "parser.add_argument('--gtscore', action='store_true', help='Use ground truth score for reverse diffusion')\n",
    "parser.add_argument('--max_iter', default=15000, type=int, help='max iterations')\n",
    "parser.add_argument('--eval_iter', default=1000, type=int, help='eval iterations')\n",
    "parser.add_argument('--fid_iter', default=2000, type=int, help='eval iterations')\n",
    "parser.add_argument('--fid_num_samples', default=100, type=int, help='eval iterations')\n",
    "parser.add_argument('--fid_bsize', default=32, type=int, help='eval iterations')\n",
    "parser.add_argument('--loss_type', type=str, default = 'multi_crop', choices=['multi_crop','sm_simple', 'eps_simple', 'sm_exact', 'std_matching'])\n",
    "parser.add_argument('--f_type', type=str, default = 'linear', choices=['linear', 'log', 'quadratic', 'cubic', 'quartic', 'triangular'])\n",
    "parser.add_argument('--dropout', default=0, type=float, help='dropout')\n",
    "\n",
    "# EMA, save\n",
    "parser.add_argument('--use_ema', action='store_true',\n",
    "                    help='use EMA or not')\n",
    "parser.add_argument('--inference', action='store_true')\n",
    "parser.add_argument('--freq_feat', action='store_true', help = \"concat Utx_i\")\n",
    "parser.add_argument('--ode', action='store_true', help = \"ODE fast sampler\")\n",
    "parser.add_argument('--ema_decay', type=float, default=0.9999, help='decay rate for EMA')\n",
    "parser.add_argument('--save_every', type=int, default=50000, help='How often we wish to save ckpts')\n",
    "opt = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c901a39",
   "metadata": {},
   "source": [
    "# 1. Set up device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7e20377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 500\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(f'cuda:{opt.gpu}')\n",
    "# device = torch.device(\"cuda:0,1,2\")\n",
    "print(\"N:\", opt.N)\n",
    "N = opt.N\n",
    "bsize = opt.bsize\n",
    "beta_min = opt.betamin\n",
    "beta_max = opt.betamax\n",
    "sig = opt.sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7411eabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae3ab4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer =  transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.5), \n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9124416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='.', train=True, transform=train_transformer, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='.', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8f7f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=opt.bsize,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=opt.bsize,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d71d3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('experiments','train')\n",
    "test_dir = os.path.join('experiments','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "088cba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write CIFAR 10 on disk\n",
    "\n",
    "# train_dataset_saved = torchvision.datasets.CIFAR10(root='.', train=True, download=True)\n",
    "# test_dataset_saved = torchvision.datasets.CIFAR10(root='.', train=False, download=True)\n",
    "\n",
    "# for idx,i in enumerate(test_dataset_saved):\n",
    "#     img, _ = i \n",
    "#     path = os.path.join(test_dir,str(idx).zfill(5)+'.png')\n",
    "#     img.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b6fc182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kietcap/anaconda3/envs/science/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/kietcap/anaconda3/envs/science/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "fid_eval = FID(real_dir =train_dir, device = device,bsize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bea7bc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains zero? tensor(False, device='cuda:0')\n",
      "blur.U_small.shape: torch.Size([32, 32])\n",
      "fs:  tensor([-0.0001,  0.0000,  0.0001,  0.0003,  0.0004,  0.0005,  0.0006,  0.0008,\n",
      "         0.0009,  0.0010,  0.0011,  0.0013,  0.0014,  0.0015,  0.0016,  0.0018,\n",
      "         0.0019,  0.0020,  0.0021,  0.0023,  0.0024,  0.0025,  0.0026,  0.0028,\n",
      "         0.0029,  0.0030,  0.0031,  0.0033,  0.0034,  0.0035,  0.0036,  0.0038,\n",
      "         0.0039,  0.0040,  0.0041,  0.0043,  0.0044,  0.0045,  0.0046,  0.0048,\n",
      "         0.0049,  0.0050,  0.0051,  0.0053,  0.0054,  0.0055,  0.0056,  0.0058,\n",
      "         0.0059,  0.0060,  0.0061,  0.0063,  0.0064,  0.0065,  0.0066,  0.0068,\n",
      "         0.0069,  0.0070,  0.0071,  0.0073,  0.0074,  0.0075,  0.0076,  0.0078,\n",
      "         0.0079,  0.0080,  0.0081,  0.0083,  0.0084,  0.0085,  0.0086,  0.0088,\n",
      "         0.0089,  0.0090,  0.0091,  0.0093,  0.0094,  0.0095,  0.0096,  0.0098,\n",
      "         0.0099,  0.0100,  0.0101,  0.0103,  0.0104,  0.0105,  0.0106,  0.0108,\n",
      "         0.0109,  0.0110,  0.0111,  0.0113,  0.0114,  0.0115,  0.0116,  0.0118,\n",
      "         0.0119,  0.0120,  0.0121,  0.0123,  0.0124,  0.0125,  0.0127,  0.0128,\n",
      "         0.0129,  0.0130,  0.0132,  0.0133,  0.0134,  0.0135,  0.0137,  0.0138,\n",
      "         0.0139,  0.0140,  0.0142,  0.0143,  0.0144,  0.0145,  0.0147,  0.0148,\n",
      "         0.0149,  0.0150,  0.0152,  0.0153,  0.0154,  0.0155,  0.0157,  0.0158,\n",
      "         0.0159,  0.0160,  0.0162,  0.0163,  0.0164,  0.0165,  0.0167,  0.0168,\n",
      "         0.0169,  0.0170,  0.0172,  0.0173,  0.0174,  0.0175,  0.0177,  0.0178,\n",
      "         0.0179,  0.0180,  0.0182,  0.0183,  0.0184,  0.0185,  0.0187,  0.0188,\n",
      "         0.0189,  0.0190,  0.0192,  0.0193,  0.0194,  0.0195,  0.0197,  0.0198,\n",
      "         0.0199,  0.0200,  0.0202,  0.0203,  0.0204,  0.0205,  0.0207,  0.0208,\n",
      "         0.0209,  0.0210,  0.0212,  0.0213,  0.0214,  0.0215,  0.0217,  0.0218,\n",
      "         0.0219,  0.0220,  0.0222,  0.0223,  0.0224,  0.0225,  0.0227,  0.0228,\n",
      "         0.0229,  0.0230,  0.0232,  0.0233,  0.0234,  0.0235,  0.0237,  0.0238,\n",
      "         0.0239,  0.0240,  0.0242,  0.0243,  0.0244,  0.0245,  0.0247,  0.0248,\n",
      "         0.0249,  0.0251,  0.0252,  0.0253,  0.0254,  0.0256,  0.0257,  0.0258,\n",
      "         0.0259,  0.0261,  0.0262,  0.0263,  0.0264,  0.0266,  0.0267,  0.0268,\n",
      "         0.0269,  0.0271,  0.0272,  0.0273,  0.0274,  0.0276,  0.0277,  0.0278,\n",
      "         0.0279,  0.0281,  0.0282,  0.0283,  0.0284,  0.0286,  0.0287,  0.0288,\n",
      "         0.0289,  0.0291,  0.0292,  0.0293,  0.0294,  0.0296,  0.0297,  0.0298,\n",
      "         0.0299,  0.0301,  0.0302,  0.0303,  0.0304,  0.0306,  0.0307,  0.0308,\n",
      "         0.0309,  0.0311,  0.0312,  0.0313,  0.0314,  0.0316,  0.0317,  0.0318,\n",
      "         0.0319,  0.0321,  0.0322,  0.0323,  0.0324,  0.0326,  0.0327,  0.0328,\n",
      "         0.0329,  0.0331,  0.0332,  0.0333,  0.0334,  0.0336,  0.0337,  0.0338,\n",
      "         0.0339,  0.0341,  0.0342,  0.0343,  0.0344,  0.0346,  0.0347,  0.0348,\n",
      "         0.0349,  0.0351,  0.0352,  0.0353,  0.0354,  0.0356,  0.0357,  0.0358,\n",
      "         0.0359,  0.0361,  0.0362,  0.0363,  0.0364,  0.0366,  0.0367,  0.0368,\n",
      "         0.0369,  0.0371,  0.0372,  0.0373,  0.0374,  0.0376,  0.0377,  0.0378,\n",
      "         0.0380,  0.0381,  0.0382,  0.0383,  0.0385,  0.0386,  0.0387,  0.0388,\n",
      "         0.0390,  0.0391,  0.0392,  0.0393,  0.0395,  0.0396,  0.0397,  0.0398,\n",
      "         0.0400,  0.0401,  0.0402,  0.0403,  0.0405,  0.0406,  0.0407,  0.0408,\n",
      "         0.0410,  0.0411,  0.0412,  0.0413,  0.0415,  0.0416,  0.0417,  0.0418,\n",
      "         0.0420,  0.0421,  0.0422,  0.0423,  0.0425,  0.0426,  0.0427,  0.0428,\n",
      "         0.0430,  0.0431,  0.0432,  0.0433,  0.0435,  0.0436,  0.0437,  0.0438,\n",
      "         0.0440,  0.0441,  0.0442,  0.0443,  0.0445,  0.0446,  0.0447,  0.0448,\n",
      "         0.0450,  0.0451,  0.0452,  0.0453,  0.0455,  0.0456,  0.0457,  0.0458,\n",
      "         0.0460,  0.0461,  0.0462,  0.0463,  0.0465,  0.0466,  0.0467,  0.0468,\n",
      "         0.0470,  0.0471,  0.0472,  0.0473,  0.0475,  0.0476,  0.0477,  0.0478,\n",
      "         0.0480,  0.0481,  0.0482,  0.0483,  0.0485,  0.0486,  0.0487,  0.0488,\n",
      "         0.0490,  0.0491,  0.0492,  0.0493,  0.0495,  0.0496,  0.0497,  0.0498,\n",
      "         0.0500,  0.0501,  0.0502,  0.0504,  0.0505,  0.0506,  0.0507,  0.0509,\n",
      "         0.0510,  0.0511,  0.0512,  0.0514,  0.0515,  0.0516,  0.0517,  0.0519,\n",
      "         0.0520,  0.0521,  0.0522,  0.0524,  0.0525,  0.0526,  0.0527,  0.0529,\n",
      "         0.0530,  0.0531,  0.0532,  0.0534,  0.0535,  0.0536,  0.0537,  0.0539,\n",
      "         0.0540,  0.0541,  0.0542,  0.0544,  0.0545,  0.0546,  0.0547,  0.0549,\n",
      "         0.0550,  0.0551,  0.0552,  0.0554,  0.0555,  0.0556,  0.0557,  0.0559,\n",
      "         0.0560,  0.0561,  0.0562,  0.0564,  0.0565,  0.0566,  0.0567,  0.0569,\n",
      "         0.0570,  0.0571,  0.0572,  0.0574,  0.0575,  0.0576,  0.0577,  0.0579,\n",
      "         0.0580,  0.0581,  0.0582,  0.0584,  0.0585,  0.0586,  0.0587,  0.0589,\n",
      "         0.0590,  0.0591,  0.0592,  0.0594,  0.0595,  0.0596,  0.0597,  0.0599,\n",
      "         0.0600,  0.0601,  0.0602,  0.0604,  0.0605,  0.0606,  0.0607,  0.0609,\n",
      "         0.0610,  0.0611,  0.0612,  0.0614,  0.0615,  0.0616,  0.0617,  0.0619,\n",
      "         0.0620,  0.0621,  0.0622,  0.0624,  0.0625], device='cuda:0')\n",
      "p:  torch.Size([501, 3072])\n",
      "D:  torch.Size([501, 3072])\n"
     ]
    }
   ],
   "source": [
    "resolution = train_dataset[0][0].shape[-1]\n",
    "input_nc = train_dataset[0][0].shape[0]\n",
    "ksize = resolution * 2 - 1\n",
    "pad = 0\n",
    "\n",
    "# define forward blur\n",
    "kernel = gaussian_kernel_1d(ksize, sig)\n",
    "blur = Deblurring(kernel, input_nc, resolution, device=device)\n",
    "print(\"blur.U_small.shape:\", blur.U_small.shape)\n",
    "D_diag = blur.singulars()\n",
    "fb = ForwardBlurIncreasing(N=N, beta_min=beta_min, beta_max=beta_max, sig=sig, sig_max = opt.sig_max, sig_min = opt.sig_min, D_diag=D_diag,\n",
    "                    blur=blur, channel=input_nc, device=device, noise_schedule=opt.noise_schedule, resolution=resolution, pad=pad, f_type=opt.f_type)\n",
    "dir = os.path.join('experiments', opt.name)\n",
    "writer = SummaryWriter(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d600cb32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_blocks torch.Size([128, 3, 3, 3])\n",
      "Let's use 3 GPUs!\n",
      "input_nc 3 resolution 32\n",
      "MAE = 3.968435976275941e-06\n",
      "x_50.std() = 0.3882894515991211\n",
      "x_50.mean() = 0.4960460662841797\n",
      "x_100.std() = 0.628707230091095\n",
      "x_100.mean() = 0.4553908705711365\n",
      "x_150.std() = 0.7928992509841919\n",
      "x_150.mean() = 0.4027232825756073\n",
      "x_200.std() = 0.896744430065155\n",
      "x_200.mean() = 0.3671554923057556\n",
      "x_250.std() = 0.9403003454208374\n",
      "x_250.mean() = 0.26846617460250854\n",
      "x_300.std() = 0.980736255645752\n",
      "x_300.mean() = 0.1915799230337143\n",
      "x_350.std() = 1.0012181997299194\n",
      "x_350.mean() = 0.12465852499008179\n",
      "x_400.std() = 0.9994067549705505\n",
      "x_400.mean() = 0.07148612290620804\n",
      "x_450.std() = 1.0067991018295288\n",
      "x_450.mean() = 0.06892959773540497\n",
      "x_500.std() = 0.9829281568527222\n",
      "x_500.mean() = 0.020680205896496773\n"
     ]
    }
   ],
   "source": [
    "model = UNetModel(resolution, input_nc, 128, input_nc, blur = blur, dropout=opt.dropout, freq_feat = opt.freq_feat)\n",
    "if not opt.ckpt == '' and os.path.exists(opt.ckpt):\n",
    "    model.load_state_dict(torch.load(opt.ckpt))\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = DataParallel(model,device_ids=[0,1,2])\n",
    "model.to(device)\n",
    "print(\"input_nc\", input_nc, \"resolution\", resolution)\n",
    "\n",
    "# data_loader = torch.utils.data.DataLoader(dataset=dataset_train,\n",
    "#                                           batch_size=bsize,\n",
    "#                                           shuffle=True,\n",
    "#                                           drop_last=True)\n",
    "# data_loader_test = torch.utils.data.DataLoader(dataset=dataset_test,\n",
    "#                                                batch_size=bsize,\n",
    "#                                                shuffle=False,\n",
    "#                                                drop_last=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=opt.lr)\n",
    "if opt.use_ema:\n",
    "    optimizer = EMA(optimizer, ema_decay=opt.ema_decay)\n",
    "\n",
    "# forward process visualization\n",
    "sample = train_dataset[1][0].unsqueeze(0)\n",
    "\n",
    "x_0 = sample[:4]\n",
    "x_0 = x_0.to(device)\n",
    "i = np.array([500] * x_0.shape[0])\n",
    "i = torch.from_numpy(i).to(device)\n",
    "fb.sanity(x_0, i)\n",
    "\n",
    "sample_list = []\n",
    "for i in range(0, N+1, N//10):\n",
    "    if i == 0:\n",
    "        sample_list.append(x_0[0])\n",
    "        continue\n",
    "    i = np.array([i] * x_0.shape[0])\n",
    "    i = torch.from_numpy(i).to(device)\n",
    "    x_i = fb.get_x_i(x_0, i)\n",
    "    sample_list.append(x_i[0])\n",
    "    print(f\"x_{i.item()}.std() = {x_i.std()}\")\n",
    "    print(f\"x_{i.item()}.mean() = {x_i.mean()}\")\n",
    "\n",
    "\n",
    "grid_sample = torch.cat(sample_list, dim=2)\n",
    "utils.tensor_imsave(grid_sample, \"./\" + dir, \"forward_process.jpg\")\n",
    "with open(os.path.join(dir, \"config.json\"), \"w\") as json_file:\n",
    "    json.dump(vars(opt), json_file)\n",
    "import time\n",
    "meta_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b204afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_distortion(s=1.0):\n",
    "    # s is the strength of color distortion.\n",
    "    color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
    "    rnd_color_jitter = transforms.RandomApply([color_jitter], p=0.8)\n",
    "    rnd_gray = transforms.RandomGrayscale(p=0.2)\n",
    "    color_distort = transforms.Compose([rnd_color_jitter, rnd_gray])\n",
    "    return color_distort\n",
    "\n",
    "class PILRandomGaussianBlur(object):\n",
    "    \"\"\"\n",
    "    Apply Gaussian Blur to the PIL image. Take the radius and probability of\n",
    "    application as the parameter.\n",
    "    This transform was used in SimCLR - https://arxiv.org/abs/2002.05709\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5, radius_min=0.1, radius_max=2.):\n",
    "        self.prob = p\n",
    "        self.radius_min = radius_min\n",
    "        self.radius_max = radius_max\n",
    "\n",
    "    def __call__(self, img):\n",
    "        do_it = np.random.rand() <= self.prob\n",
    "        if not do_it:\n",
    "            return img\n",
    "\n",
    "        return img.filter(\n",
    "            ImageFilter.GaussianBlur(\n",
    "                radius=random.uniform(self.radius_min, self.radius_max)\n",
    "            )\n",
    "        )\n",
    "\n",
    "class MultiCropDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path,\n",
    "        size_crops,\n",
    "        nmb_crops,\n",
    "        min_scale_crops,\n",
    "        max_scale_crops,\n",
    "        size_dataset=-1,\n",
    "        return_index=False,\n",
    "    ):\n",
    "#         super(MultiCropDataset, self).__init__()\n",
    "        assert len(size_crops) == len(nmb_crops)\n",
    "        assert len(min_scale_crops) == len(nmb_crops)\n",
    "        assert len(max_scale_crops) == len(nmb_crops)\n",
    "#         if size_dataset >= 0:\n",
    "#             self.samples = self.samples[:size_dataset]\n",
    "            \n",
    "        self.list_image_paths = [os.path.join(data_path,i) for i in os.listdir(data_path)]\n",
    "        self.return_index = return_index\n",
    "\n",
    "        color_transform = [get_color_distortion(), PILRandomGaussianBlur()]\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.228, 0.224, 0.225]\n",
    "        trans = []\n",
    "        for i in range(len(size_crops)):\n",
    "            randomresizedcrop = transforms.RandomResizedCrop(\n",
    "                size_crops[i],\n",
    "                scale=(min_scale_crops[i], max_scale_crops[i]),\n",
    "            )\n",
    "            trans.extend([transforms.Compose([\n",
    "                randomresizedcrop,\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.Compose(color_transform),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=mean, std=std)])\n",
    "            ] * nmb_crops[i])\n",
    "        self.trans = trans\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path = self.list_image_paths[index]\n",
    "        image = Image.open(path)\n",
    "        multi_crops = list(map(lambda trans: trans(image), self.trans))\n",
    "        if self.return_index:\n",
    "            return index, multi_crops\n",
    "        return multi_crops\n",
    "    def __len__(self):\n",
    "        return len(self.list_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e8dc8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "multicrop_dataset = MultiCropDataset(train_dir,size_crops=[28,16],nmb_crops=[2,6],min_scale_crops=[0.14, 0.05]\n",
    "                                     ,max_scale_crops=[1., 0.14])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9eaa2252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans():\n",
    "    size_crops=[28,16]\n",
    "    nmb_crops=[2,6]\n",
    "    min_scale_crops=[0.14, 0.05]\n",
    "    max_scale_crops=[1., 0.14]  \n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.228, 0.224, 0.225]\n",
    "    color_transform = [get_color_distortion(), PILRandomGaussianBlur()]\n",
    "    trans=[]\n",
    "    for i in range(len(size_crops)):\n",
    "        randomresizedcrop = transforms.RandomResizedCrop(\n",
    "            size_crops[i],\n",
    "            scale=(min_scale_crops[i], max_scale_crops[i]),\n",
    "        )\n",
    "        trans.extend([transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            randomresizedcrop,\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.Compose(color_transform),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)])\n",
    "        ] * nmb_crops[i])\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41eba76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((3,3,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9c7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(14.0729, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for step in range(opt.max_iter):\n",
    "    if not opt.inference:\n",
    "        elips = time.time()\n",
    "        try:\n",
    "            x_0, _ = train_iter.next()\n",
    "        except:\n",
    "            train_iter = iter(train_loader)\n",
    "            image, _ = next(train_iter)\n",
    "        \"\"\"\n",
    "        training\n",
    "        \"\"\"\n",
    "        assert x_0.shape[-1] == resolution, f\"{x_0.shape}\"\n",
    "        i = np.random.uniform(1 / N, 1, size = (x_0.shape[0])) * N\n",
    "        i = torch.from_numpy(i).to(device).type(torch.long)\n",
    "        x_0 = x_0.to(device)\n",
    "\n",
    "        multi_crops_list = []\n",
    "        for x_temp in x_0:\n",
    "            multi_crops = list(map(lambda trans: trans(x_temp), trans()))\n",
    "            multi_crops_list.append(multi_crops)\n",
    "        batch_x_i = []\n",
    "        for multi_crops in multi_crops_list:\n",
    "            x_i_list = []\n",
    "            pad_size = []\n",
    "            for crop in multi_crops:\n",
    "                pad = (x_0.shape[2] - crop.shape[1]) // 2\n",
    "                pad_size.append(pad)\n",
    "                padded_crop = torch.nn.functional.pad(crop,(pad,pad,pad,pad),'constant',-1)\n",
    "#                 x_i, eps = fb.get_x_i(padded_crop, i, return_eps = True)\n",
    "#                 eps_list.append(eps)  \n",
    "                x_i_list.append(padded_crop)\n",
    "            x_i_stack = torch.stack(x_i_list)            \n",
    "            batch_x_i.append(x_i_stack)\n",
    "            \n",
    "        batch_x_i = torch.stack(batch_x_i)\n",
    "        views = []\n",
    "        x_i_views, eps_views = [],[]\n",
    "        for idx in range(batch_x_i.shape[1]):\n",
    "#             view.append(batch_x_i[:,i])\n",
    "            x_i_view, eps_view = fb.get_x_i(batch_x_i[:,idx].to(device), i, return_eps = True)\n",
    "            x_i_view_depad = torch.nn.functional.pad(x_i_view,(-pad_size[idx],-pad_size[idx],-pad_size[idx],-pad_size[idx]),'constant',-1)\n",
    "            x_i_views.append(x_i_view_depad)\n",
    "            eps_views.append(eps_view)\n",
    "            \n",
    "         \n",
    "        if opt.loss_type == \"sm_simple\":\n",
    "            loss = fb.get_loss_i_simple(model, x_0, x_i, i)\n",
    "        elif opt.loss_type == \"eps_simple\":\n",
    "            loss = fb.get_loss_i_eps_simple(model, x_i, i, eps_views)\n",
    "        elif opt.loss_type == \"sm_exact\":\n",
    "            loss = fb.get_loss_i_exact(model, x_0, x_i, i)\n",
    "        elif opt.loss_type == \"std_matching\":\n",
    "            loss = fb.get_loss_i_std_matching(model, x_i, i, eps_views)\n",
    "        elif opt.loss_type ==\"multi_crop\":\n",
    "            loss = fb.get_loss_i_multi_crop(model,x_i_views,i,eps_views,pad_size)\n",
    "        \n",
    "        writer.add_scalar('loss_train', loss, step)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if step % 100 == 0:\n",
    "            print(step, loss)\n",
    "        # print(f\"time: {time.time() - elips}\")\n",
    "    # Calcuate FID\n",
    "    if step > 2401:\n",
    "        fid_iter = opt.fid_iter\n",
    "    else:\n",
    "        fid_iter = 2400\n",
    "    if (step % fid_iter == 0 and step > 0):\n",
    "        id = 0\n",
    "        if not os.path.exists(os.path.join(\"./\",dir, f\"{step}\")):\n",
    "            os.mkdir(os.path.join(\"./\",dir, f\"{step}\"))\n",
    "        with torch.no_grad():\n",
    "            if opt.use_ema:\n",
    "                optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "            model = model.eval()\n",
    "            for _ in range(opt.fid_num_samples // opt.fid_bsize):\n",
    "                i = np.array([opt.N - 1] * opt.fid_bsize)\n",
    "                i = torch.from_numpy(i).to(device)\n",
    "                pred = fb.get_x_N([opt.fid_bsize, input_nc, resolution, resolution], i)\n",
    "                for i in reversed(range(1, opt.N)):\n",
    "                    i = np.array([i] * opt.fid_bsize)\n",
    "                    i = torch.from_numpy(i).to(device)\n",
    "                    if opt.loss_type == \"sm_simple\":\n",
    "                        s = model(pred, i)\n",
    "                    elif opt.loss_type == \"eps_simple\":\n",
    "                        eps = model(pred, i)\n",
    "                        s = fb.get_score_from_eps(eps, i)\n",
    "                    elif opt.loss_type == \"sm_exact\":\n",
    "                        s = model(pred, i)\n",
    "                    elif opt.loss_type == \"std_matching\":\n",
    "                        std = model(pred, i)\n",
    "                        s = fb.get_score_from_std(std, i)\n",
    "                    else:\n",
    "                        eps = model(pred, i)\n",
    "                        s = fb.get_score_from_eps(eps, i)\n",
    "#                         raise NotImplementedError\n",
    "                    s = fb.U_I_minus_B_Ut(s, i)\n",
    "                    rms = lambda x: torch.sqrt(torch.mean(x ** 2))\n",
    "                    # print(f\"rms(s) * fb._beta_i(i) = {rms(s) * fb._beta_i(i)[0]}\")\n",
    "                    hf = pred - fb.W(pred, i)\n",
    "                    # Anderson theorem\n",
    "                    pred1 = pred + hf # unsharpening mask filtering\n",
    "                    pred2 = pred1 + s  # # denoising\n",
    "                    if i[0] > 2:\n",
    "                        pred = pred2 + fb.U_I_minus_B_sqrt_Ut(torch.randn_like(pred), i) # inject noise\n",
    "                    else:\n",
    "                        pred = pred2\n",
    "                    # print(f\"i = {i[0]}, rmse = {torch.sqrt(torch.mean(pred**2))}, mean = {torch.mean(pred)} std = {torch.std(pred)}\" )\n",
    "                for sample in pred:\n",
    "                    save_image(sample, os.path.join(dir, f\"{step}\", f\"{id:05d}.png\"))\n",
    "                    id += 1\n",
    "        if opt.use_ema:\n",
    "            optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "            model = model.train()\n",
    "        fid = fid_eval(os.path.join(dir, f\"{step}\"))\n",
    "        writer.add_scalar('fid', fid, step)\n",
    "        print(f\"step {step}, fid = {fid}\")\n",
    "    if (step % opt.eval_iter == 0 and step > 0) or opt.inference:\n",
    "        \"\"\"\n",
    "        sampling (eval)\n",
    "        \"\"\"\n",
    "        cnt = 0\n",
    "        loss = 0\n",
    "        \n",
    "\n",
    "        with torch.no_grad():\n",
    "            if opt.use_ema:\n",
    "                optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "            model = model.eval()\n",
    "\n",
    "            if opt.ode:\n",
    "                raise NotImplementedError\n",
    "                def to_flattened_numpy(x):\n",
    "                    \"\"\"Flatten a torch tensor `x` and convert it to numpy.\"\"\"\n",
    "                    return x.detach().cpu().numpy().reshape((-1,))\n",
    "                def from_flattened_numpy(x, shape):\n",
    "                    \"\"\"Form a torch tensor with the given `shape` from a flattened numpy array `x`.\"\"\"\n",
    "                    return torch.from_numpy(x.reshape(shape))\n",
    "                def ode_func(i, y):\n",
    "                    i = int(i*N)\n",
    "                    print(f\"i = {i}\")\n",
    "                    y = from_flattened_numpy(y, [bsize, input_nc, resolution, resolution]).to(device).type(torch.float32)\n",
    "                    i = np.array([N - 1] * bsize)\n",
    "                    i = torch.from_numpy(i).to(device)\n",
    "                    if opt.loss_type == \"sm_simple\":\n",
    "                            s = model(y, i)\n",
    "                    elif opt.loss_type == \"eps_simple\":\n",
    "                        eps = model(y, i)\n",
    "                        s = fb.get_score_from_eps(eps, i)\n",
    "                    elif opt.loss_type == \"sm_exact\":\n",
    "                        s = model(y, i)\n",
    "                    elif opt.loss_type == \"std_matching\":\n",
    "                        std = model(y, i)\n",
    "                        s = fb.get_score_from_std(std, i)\n",
    "                    else:\n",
    "                        eps = model(pred, i)\n",
    "                        s = fb.get_score_from_eps(eps, i)\n",
    "#                         raise NotImplementedError\n",
    "                    s = fb.U_I_minus_B_Ut(s, i)\n",
    "                    hf = y - fb.W(y, i)\n",
    "                    dt = - 1.0 / N\n",
    "                    drift = (s/2 + hf) / dt\n",
    "                    drift = to_flattened_numpy(drift)\n",
    "                    return drift\n",
    "                x_N = fb.get_x_N([bsize, input_nc, resolution, resolution], N)\n",
    "                solution = solve_ivp(ode_func, (1, 1e-3), to_flattened_numpy(x_N),\n",
    "                                     rtol=1e-3, atol=1e-3, method=\"RK45\")\n",
    "                nfe = solution.nfev\n",
    "                solution = torch.tensor(solution.y[:, -1]).reshape(x_N.shape).to(device).type(torch.float32)\n",
    "                \n",
    "                save_image(solution, \"./solution.jpg\")\n",
    "                print(f\"nfe = {nfe}\")\n",
    "                raise NotImplementedError\n",
    "            for x_0, _ in test_loader:\n",
    "                x_0 = x_0.to(device)\n",
    "                # for v in range(0, 250, 20):\n",
    "                #     x_0[:, :, v, :] = 0\n",
    "                if opt.fromprior:\n",
    "                    i = np.array([N - 1] * x_0.shape[0])\n",
    "                    i = torch.from_numpy(i).to(device)\n",
    "                    pred = fb.get_x_N(x_0.shape, i)\n",
    "                    print(f\"pred.std() = {pred.std()}\")\n",
    "                else:\n",
    "                    i = np.array([N-1] * x_0.shape[0])\n",
    "                    i = torch.from_numpy(i).to(device)\n",
    "                    pred = fb.get_x_i(x_0, i)\n",
    "                preds = [pred]\n",
    "\n",
    "                for i in reversed(range(1, N)):\n",
    "                    i = np.array([i] * x_0.shape[0])\n",
    "                    i = torch.from_numpy(i).to(device)\n",
    "                    if opt.gtscore:\n",
    "                        s = fb.get_score_gt(pred, x_0, i)\n",
    "                    else:\n",
    "                        if opt.loss_type == \"sm_simple\":\n",
    "                            s = model(pred, i)\n",
    "                        elif opt.loss_type == \"eps_simple\":\n",
    "                            eps = model(pred, i)\n",
    "                            s = fb.get_score_from_eps(eps, i)\n",
    "                        elif opt.loss_type == \"sm_exact\":\n",
    "                            s = model(pred, i)\n",
    "                        elif opt.loss_type == \"std_matching\":\n",
    "                            std = model(pred, i)\n",
    "                            s = fb.get_score_from_std(std, i)\n",
    "                        else:\n",
    "                            eps = model(pred, i)\n",
    "                            s = fb.get_score_from_eps(eps, i)\n",
    "#                             raise NotImplementedError\n",
    "                    s = fb.U_I_minus_B_Ut(s, i)\n",
    "                    rms = lambda x: torch.sqrt(torch.mean(x ** 2))\n",
    "                    # print(f\"rms(s) * fb._beta_i(i) = {rms(s) * fb._beta_i(i)[0]}\")\n",
    "                    hf = pred - fb.W(pred, i)\n",
    "                    # Anderson theorem\n",
    "                    pred1 = pred + hf # unsharpening mask filtering\n",
    "                    pred2 = pred1 + s  # # denoising\n",
    "                    if i[0] > 2:\n",
    "                        pred = pred2 + fb.U_I_minus_B_sqrt_Ut(torch.randn_like(pred), i) # inject noise\n",
    "                    else:\n",
    "                        pred = pred2\n",
    "                    # print(f\"i = {i[0]}, rmse = {torch.sqrt(torch.mean(pred**2))}, mean = {torch.mean(pred)} std = {torch.std(pred)}\")\n",
    "                    # assert rms(pred) < 100\n",
    "                    if (i[0]) % (N // 10) == 0:\n",
    "                        img = pred[0]\n",
    "                        preds.append(pred)\n",
    "\n",
    "                preds.append(pred)\n",
    "                assert x_0.shape == pred.shape\n",
    "                # visualize\n",
    "                grid = torch.cat(preds, dim=3) # grid_sample.shape: (bsize, channel, H, W * 12)\n",
    "                # (batch_size, channel, H, W * 12) -> (channel, H * bsize, W * 12)\n",
    "                grid = grid.permute(1, 0, 2, 3).contiguous().view(grid.shape[1], -1, grid.shape[3])\n",
    "                # (bsize, channel, H, W) -> (channel, H, W * bsize)\n",
    "                gt = x_0.permute(1, 2, 0, 3).contiguous().view(x_0.shape[1], -1, x_0.shape[3] * x_0.shape[0])\n",
    "                if cnt <= 2:\n",
    "                    utils.tensor_imsave(gt, \"./\" + dir, f\"{step}_{cnt}_GT.jpg\")\n",
    "                    utils.tensor_imsave(grid, \"./\" + dir, f\"{step}_{cnt}_pred.jpg\")\n",
    "              \n",
    "                cnt += 1\n",
    "                loss += TF.l1_loss(x_0, pred) / 2\n",
    "\n",
    "                if cnt == 2:\n",
    "                    break\n",
    "        print(f\"step: {step} loss: {loss}\")\n",
    "        writer.add_scalar('loss_val', loss, meta_iter)\n",
    "        f = open('./' + str(dir) + '/log.txt', 'a')\n",
    "\n",
    "        f.write(f\"Step: {step} loss: {loss}\" + '\\n')\n",
    "\n",
    "        f.close()\n",
    "        model.train()\n",
    "        if opt.use_ema:\n",
    "            optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "    if step % opt.save_every == 1:\n",
    "        if opt.use_ema:\n",
    "            optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            torch.save(model.module.state_dict(), os.path.join(dir, f\"model_{step}.ckpt\"))\n",
    "        else:\n",
    "            torch.save(model.state_dict(), os.path.join(dir, f\"model_{step}.ckpt\"))\n",
    "        if opt.use_ema:\n",
    "            optimizer.swap_parameters_with_ema(store_params_in_ema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f395a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for step in range(opt.max_iter):\n",
    "#     if not opt.inference:\n",
    "#         elips = time.time()\n",
    "#         try:\n",
    "#             x_0, _ = train_iter.next()\n",
    "#         except:\n",
    "#             train_iter = iter(train_loader)\n",
    "#             image, _ = next(train_iter)\n",
    "#         \"\"\"\n",
    "#         training\n",
    "#         \"\"\"\n",
    "#         assert x_0.shape[-1] == resolution, f\"{x_0.shape}\"\n",
    "#         i = np.random.uniform(1 / N, 1, size = (x_0.shape[0])) * N\n",
    "#         i = torch.from_numpy(i).to(device).type(torch.long)\n",
    "\n",
    "#         x_0 = x_0.to(device)\n",
    "#         x_i, eps = fb.get_x_i(x_0, i, return_eps = True)\n",
    "\n",
    "#         if opt.loss_type == \"sm_simple\":\n",
    "#             loss = fb.get_loss_i_simple(model, x_0, x_i, i)\n",
    "#         elif opt.loss_type == \"eps_simple\":\n",
    "#             loss = fb.get_loss_i_eps_simple(model, x_i, i, eps)\n",
    "#         elif opt.loss_type == \"sm_exact\":\n",
    "#             loss = fb.get_loss_i_exact(model, x_0, x_i, i)\n",
    "#         elif opt.loss_type == \"std_matching\":\n",
    "#             loss = fb.get_loss_i_std_matching(model, x_i, i, eps)\n",
    "#         writer.add_scalar('loss_train', loss, step)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "#         if step % 100 == 0:\n",
    "#             print(step, loss)\n",
    "#         # print(f\"time: {time.time() - elips}\")\n",
    "#     # Calcuate FID\n",
    "#     if step > 240001:\n",
    "#         fid_iter = opt.fid_iter\n",
    "#     else:\n",
    "#         fid_iter = 240000\n",
    "#     if (step % fid_iter == 0 and step > 0):\n",
    "#         id = 0\n",
    "#         if not os.path.exists(os.path.join(\"./\",dir, f\"{step}\")):\n",
    "#             os.mkdir(os.path.join(\"./\",dir, f\"{step}\"))\n",
    "#         with torch.no_grad():\n",
    "#             if opt.use_ema:\n",
    "#                 optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "#             model = model.eval()\n",
    "#             for _ in range(opt.fid_num_samples // opt.fid_bsize):\n",
    "#                 i = np.array([opt.N - 1] * opt.fid_bsize)\n",
    "#                 i = torch.from_numpy(i).to(device)\n",
    "#                 pred = fb.get_x_N([opt.fid_bsize, input_nc, resolution, resolution], i)\n",
    "#                 for i in reversed(range(1, opt.N)):\n",
    "#                     i = np.array([i] * opt.fid_bsize)\n",
    "#                     i = torch.from_numpy(i).to(device)\n",
    "#                     if opt.loss_type == \"sm_simple\":\n",
    "#                         s = model(pred, i)\n",
    "#                     elif opt.loss_type == \"eps_simple\":\n",
    "#                         eps = model(pred, i)\n",
    "#                         s = fb.get_score_from_eps(eps, i)\n",
    "#                     elif opt.loss_type == \"sm_exact\":\n",
    "#                         s = model(pred, i)\n",
    "#                     elif opt.loss_type == \"std_matching\":\n",
    "#                         std = model(pred, i)\n",
    "#                         s = fb.get_score_from_std(std, i)\n",
    "#                     else:\n",
    "#                         raise NotImplementedError\n",
    "#                     s = fb.U_I_minus_B_Ut(s, i)\n",
    "#                     rms = lambda x: torch.sqrt(torch.mean(x ** 2))\n",
    "#                     # print(f\"rms(s) * fb._beta_i(i) = {rms(s) * fb._beta_i(i)[0]}\")\n",
    "#                     hf = pred - fb.W(pred, i)\n",
    "#                     # Anderson theorem\n",
    "#                     pred1 = pred + hf # unsharpening mask filtering\n",
    "#                     pred2 = pred1 + s  # # denoising\n",
    "#                     if i[0] > 2:\n",
    "#                         pred = pred2 + fb.U_I_minus_B_sqrt_Ut(torch.randn_like(pred), i) # inject noise\n",
    "#                     else:\n",
    "#                         pred = pred2\n",
    "#                     # print(f\"i = {i[0]}, rmse = {torch.sqrt(torch.mean(pred**2))}, mean = {torch.mean(pred)} std = {torch.std(pred)}\" )\n",
    "#                 for sample in pred:\n",
    "#                     save_image(sample, os.path.join(dir, f\"{step}\", f\"{id:05d}.png\"))\n",
    "#                     id += 1\n",
    "#         if opt.use_ema:\n",
    "#             optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "#             model = model.train()\n",
    "#         fid = fid_eval(os.path.join(dir, f\"{step}\"))\n",
    "#         writer.add_scalar('fid', fid, step)\n",
    "#         print(f\"step {step}, fid = {fid}\")\n",
    "#     if (step % opt.eval_iter == 0 and step > 0) or opt.inference:\n",
    "#         \"\"\"\n",
    "#         sampling (eval)\n",
    "#         \"\"\"\n",
    "#         cnt = 0\n",
    "#         loss = 0\n",
    "        \n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             if opt.use_ema:\n",
    "#                 optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "#             model = model.eval()\n",
    "\n",
    "#             if opt.ode:\n",
    "#                 raise NotImplementedError\n",
    "#                 def to_flattened_numpy(x):\n",
    "#                     \"\"\"Flatten a torch tensor `x` and convert it to numpy.\"\"\"\n",
    "#                     return x.detach().cpu().numpy().reshape((-1,))\n",
    "#                 def from_flattened_numpy(x, shape):\n",
    "#                     \"\"\"Form a torch tensor with the given `shape` from a flattened numpy array `x`.\"\"\"\n",
    "#                     return torch.from_numpy(x.reshape(shape))\n",
    "#                 def ode_func(i, y):\n",
    "#                     i = int(i*N)\n",
    "#                     print(f\"i = {i}\")\n",
    "#                     y = from_flattened_numpy(y, [bsize, input_nc, resolution, resolution]).to(device).type(torch.float32)\n",
    "#                     i = np.array([N - 1] * bsize)\n",
    "#                     i = torch.from_numpy(i).to(device)\n",
    "#                     if opt.loss_type == \"sm_simple\":\n",
    "#                             s = model(y, i)\n",
    "#                     elif opt.loss_type == \"eps_simple\":\n",
    "#                         eps = model(y, i)\n",
    "#                         s = fb.get_score_from_eps(eps, i)\n",
    "#                     elif opt.loss_type == \"sm_exact\":\n",
    "#                         s = model(y, i)\n",
    "#                     elif opt.loss_type == \"std_matching\":\n",
    "#                         std = model(y, i)\n",
    "#                         s = fb.get_score_from_std(std, i)\n",
    "#                     else:\n",
    "#                         raise NotImplementedError\n",
    "#                     s = fb.U_I_minus_B_Ut(s, i)\n",
    "#                     hf = y - fb.W(y, i)\n",
    "#                     dt = - 1.0 / N\n",
    "#                     drift = (s/2 + hf) / dt\n",
    "#                     drift = to_flattened_numpy(drift)\n",
    "#                     return drift\n",
    "#                 x_N = fb.get_x_N([bsize, input_nc, resolution, resolution], N)\n",
    "#                 solution = solve_ivp(ode_func, (1, 1e-3), to_flattened_numpy(x_N),\n",
    "#                                      rtol=1e-3, atol=1e-3, method=\"RK45\")\n",
    "#                 nfe = solution.nfev\n",
    "#                 solution = torch.tensor(solution.y[:, -1]).reshape(x_N.shape).to(device).type(torch.float32)\n",
    "                \n",
    "#                 save_image(solution, \"./solution.jpg\")\n",
    "#                 print(f\"nfe = {nfe}\")\n",
    "#                 raise NotImplementedError\n",
    "#             for x_0, _ in test_loader:\n",
    "#                 x_0 = x_0.to(device)\n",
    "#                 # for v in range(0, 250, 20):\n",
    "#                 #     x_0[:, :, v, :] = 0\n",
    "#                 if opt.fromprior:\n",
    "#                     i = np.array([N - 1] * x_0.shape[0])\n",
    "#                     i = torch.from_numpy(i).to(device)\n",
    "#                     pred = fb.get_x_N(x_0.shape, i)\n",
    "#                     print(f\"pred.std() = {pred.std()}\")\n",
    "#                 else:\n",
    "#                     i = np.array([N-1] * x_0.shape[0])\n",
    "#                     i = torch.from_numpy(i).to(device)\n",
    "#                     pred = fb.get_x_i(x_0, i)\n",
    "#                 preds = [pred]\n",
    "\n",
    "#                 for i in reversed(range(1, N)):\n",
    "#                     i = np.array([i] * x_0.shape[0])\n",
    "#                     i = torch.from_numpy(i).to(device)\n",
    "#                     if opt.gtscore:\n",
    "#                         s = fb.get_score_gt(pred, x_0, i)\n",
    "#                     else:\n",
    "#                         if opt.loss_type == \"sm_simple\":\n",
    "#                             s = model(pred, i)\n",
    "#                         elif opt.loss_type == \"eps_simple\":\n",
    "#                             eps = model(pred, i)\n",
    "#                             s = fb.get_score_from_eps(eps, i)\n",
    "#                         elif opt.loss_type == \"sm_exact\":\n",
    "#                             s = model(pred, i)\n",
    "#                         elif opt.loss_type == \"std_matching\":\n",
    "#                             std = model(pred, i)\n",
    "#                             s = fb.get_score_from_std(std, i)\n",
    "#                         else:\n",
    "#                             raise NotImplementedError\n",
    "#                     s = fb.U_I_minus_B_Ut(s, i)\n",
    "#                     rms = lambda x: torch.sqrt(torch.mean(x ** 2))\n",
    "#                     # print(f\"rms(s) * fb._beta_i(i) = {rms(s) * fb._beta_i(i)[0]}\")\n",
    "#                     hf = pred - fb.W(pred, i)\n",
    "#                     # Anderson theorem\n",
    "#                     pred1 = pred + hf # unsharpening mask filtering\n",
    "#                     pred2 = pred1 + s  # # denoising\n",
    "#                     if i[0] > 2:\n",
    "#                         pred = pred2 + fb.U_I_minus_B_sqrt_Ut(torch.randn_like(pred), i) # inject noise\n",
    "#                     else:\n",
    "#                         pred = pred2\n",
    "#                     # print(f\"i = {i[0]}, rmse = {torch.sqrt(torch.mean(pred**2))}, mean = {torch.mean(pred)} std = {torch.std(pred)}\")\n",
    "#                     # assert rms(pred) < 100\n",
    "#                     if (i[0]) % (N // 10) == 0:\n",
    "#                         img = pred[0]\n",
    "#                         preds.append(pred)\n",
    "\n",
    "#                 preds.append(pred)\n",
    "#                 assert x_0.shape == pred.shape\n",
    "#                 # visualize\n",
    "#                 grid = torch.cat(preds, dim=3) # grid_sample.shape: (bsize, channel, H, W * 12)\n",
    "#                 # (batch_size, channel, H, W * 12) -> (channel, H * bsize, W * 12)\n",
    "#                 grid = grid.permute(1, 0, 2, 3).contiguous().view(grid.shape[1], -1, grid.shape[3])\n",
    "#                 # (bsize, channel, H, W) -> (channel, H, W * bsize)\n",
    "#                 gt = x_0.permute(1, 2, 0, 3).contiguous().view(x_0.shape[1], -1, x_0.shape[3] * x_0.shape[0])\n",
    "#                 if cnt <= 2:\n",
    "#                     utils.tensor_imsave(gt, \"./\" + dir, f\"{step}_{cnt}_GT.jpg\")\n",
    "#                     utils.tensor_imsave(grid, \"./\" + dir, f\"{step}_{cnt}_pred.jpg\")\n",
    "              \n",
    "#                 cnt += 1\n",
    "#                 loss += TF.l1_loss(x_0, pred) / 2\n",
    "\n",
    "#                 if cnt == 2:\n",
    "#                     break\n",
    "#         print(f\"step: {step} loss: {loss}\")\n",
    "#         writer.add_scalar('loss_val', loss, meta_iter)\n",
    "#         f = open('./' + str(dir) + '/log.txt', 'a')\n",
    "\n",
    "#         f.write(f\"Step: {step} loss: {loss}\" + '\\n')\n",
    "\n",
    "#         f.close()\n",
    "#         model.train()\n",
    "#         if opt.use_ema:\n",
    "#             optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "#     if step % opt.save_every == 1:\n",
    "#         if opt.use_ema:\n",
    "#             optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "#         if torch.cuda.device_count() > 1:\n",
    "#             torch.save(model.module.state_dict(), os.path.join(dir, f\"model_{step}.ckpt\"))\n",
    "#         else:\n",
    "#             torch.save(model.state_dict(), os.path.join(dir, f\"model_{step}.ckpt\"))\n",
    "#         if opt.use_ema:\n",
    "#             optimizer.swap_parameters_with_ema(store_params_in_ema=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb1f3459",
   "metadata": {},
   "source": [
    "# for step in range(opt.max_iter):\n",
    "#     if not opt.inference:\n",
    "#         elips = time.time()\n",
    "#         try:\n",
    "#             x_0, _ = train_iter.next()\n",
    "#         except:\n",
    "#             train_iter = iter(train_loader)\n",
    "#             image, _ = next(train_iter)\n",
    "#         \"\"\"\n",
    "#         training\n",
    "#         \"\"\"\n",
    "#         assert x_0.shape[-1] == resolution, f\"{x_0.shape}\"\n",
    "#         i = np.random.uniform(1 / N, 1, size = (x_0.shape[0])) * N\n",
    "#         i = torch.from_numpy(i).to(device).type(torch.long)\n",
    "\n",
    "#         x_0 = x_0.to(device)\n",
    "#         x_i, eps = fb.get_x_i(x_0, i, return_eps = True)\n",
    "\n",
    "#         if opt.loss_type == \"sm_simple\":\n",
    "#             loss = fb.get_loss_i_simple(model, x_0, x_i, i)\n",
    "#         elif opt.loss_type == \"eps_simple\":\n",
    "#             loss = fb.get_loss_i_eps_simple(model, x_i, i, eps)\n",
    "#         elif opt.loss_type == \"sm_exact\":\n",
    "#             loss = fb.get_loss_i_exact(model, x_0, x_i, i)\n",
    "#         elif opt.loss_type == \"std_matching\":\n",
    "#             loss = fb.get_loss_i_std_matching(model, x_i, i, eps)\n",
    "#         writer.add_scalar('loss_train', loss, step)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "#         if step % 100 == 0:\n",
    "#             print(step, loss)\n",
    "#         # print(f\"time: {time.time() - elips}\")\n",
    "#     # Calcuate FID\n",
    "#     if step > 240001:\n",
    "#         fid_iter = opt.fid_iter\n",
    "#     else:\n",
    "#         fid_iter = 240000\n",
    "#     if (step % fid_iter == 0 and step > 0):\n",
    "#         id = 0\n",
    "#         if not os.path.exists(os.path.join(\"./\",dir, f\"{step}\")):\n",
    "#             os.mkdir(os.path.join(\"./\",dir, f\"{step}\"))\n",
    "#         with torch.no_grad():\n",
    "#             if opt.use_ema:\n",
    "#                 optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "#             model = model.eval()\n",
    "#             for _ in range(opt.fid_num_samples // opt.fid_bsize):\n",
    "#                 i = np.array([opt.N - 1] * opt.fid_bsize)\n",
    "#                 i = torch.from_numpy(i).to(device)\n",
    "#                 pred = fb.get_x_N([opt.fid_bsize, input_nc, resolution, resolution], i)\n",
    "#                 for i in reversed(range(1, opt.N)):\n",
    "#                     i = np.array([i] * opt.fid_bsize)\n",
    "#                     i = torch.from_numpy(i).to(device)\n",
    "#                     if opt.loss_type == \"sm_simple\":\n",
    "#                         s = model(pred, i)\n",
    "#                     elif opt.loss_type == \"eps_simple\":\n",
    "#                         eps = model(pred, i)\n",
    "#                         s = fb.get_score_from_eps(eps, i)\n",
    "#                     elif opt.loss_type == \"sm_exact\":\n",
    "#                         s = model(pred, i)\n",
    "#                     elif opt.loss_type == \"std_matching\":\n",
    "#                         std = model(pred, i)\n",
    "#                         s = fb.get_score_from_std(std, i)\n",
    "#                     else:\n",
    "#                         raise NotImplementedError\n",
    "#                     s = fb.U_I_minus_B_Ut(s, i)\n",
    "#                     rms = lambda x: torch.sqrt(torch.mean(x ** 2))\n",
    "#                     # print(f\"rms(s) * fb._beta_i(i) = {rms(s) * fb._beta_i(i)[0]}\")\n",
    "#                     hf = pred - fb.W(pred, i)\n",
    "#                     # Anderson theorem\n",
    "#                     pred1 = pred + hf # unsharpening mask filtering\n",
    "#                     pred2 = pred1 + s  # # denoising\n",
    "#                     if i[0] > 2:\n",
    "#                         pred = pred2 + fb.U_I_minus_B_sqrt_Ut(torch.randn_like(pred), i) # inject noise\n",
    "#                     else:\n",
    "#                         pred = pred2\n",
    "#                     # print(f\"i = {i[0]}, rmse = {torch.sqrt(torch.mean(pred**2))}, mean = {torch.mean(pred)} std = {torch.std(pred)}\" )\n",
    "#                 for sample in pred:\n",
    "#                     save_image(sample, os.path.join(dir, f\"{step}\", f\"{id:05d}.png\"))\n",
    "#                     id += 1\n",
    "#         if opt.use_ema:\n",
    "#             optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "#             model = model.train()\n",
    "#         fid = fid_eval(os.path.join(dir, f\"{step}\"))\n",
    "#         writer.add_scalar('fid', fid, step)\n",
    "#         print(f\"step {step}, fid = {fid}\")\n",
    "#     if (step % opt.eval_iter == 0 and step > 0) or opt.inference:\n",
    "#         \"\"\"\n",
    "#         sampling (eval)\n",
    "#         \"\"\"\n",
    "#         cnt = 0\n",
    "#         loss = 0\n",
    "        \n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             if opt.use_ema:\n",
    "#                 optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "#             model = model.eval()\n",
    "\n",
    "#             if opt.ode:\n",
    "#                 raise NotImplementedError\n",
    "#                 def to_flattened_numpy(x):\n",
    "#                     \"\"\"Flatten a torch tensor `x` and convert it to numpy.\"\"\"\n",
    "#                     return x.detach().cpu().numpy().reshape((-1,))\n",
    "#                 def from_flattened_numpy(x, shape):\n",
    "#                     \"\"\"Form a torch tensor with the given `shape` from a flattened numpy array `x`.\"\"\"\n",
    "#                     return torch.from_numpy(x.reshape(shape))\n",
    "#                 def ode_func(i, y):\n",
    "#                     i = int(i*N)\n",
    "#                     print(f\"i = {i}\")\n",
    "#                     y = from_flattened_numpy(y, [bsize, input_nc, resolution, resolution]).to(device).type(torch.float32)\n",
    "#                     i = np.array([N - 1] * bsize)\n",
    "#                     i = torch.from_numpy(i).to(device)\n",
    "#                     if opt.loss_type == \"sm_simple\":\n",
    "#                             s = model(y, i)\n",
    "#                     elif opt.loss_type == \"eps_simple\":\n",
    "#                         eps = model(y, i)\n",
    "#                         s = fb.get_score_from_eps(eps, i)\n",
    "#                     elif opt.loss_type == \"sm_exact\":\n",
    "#                         s = model(y, i)\n",
    "#                     elif opt.loss_type == \"std_matching\":\n",
    "#                         std = model(y, i)\n",
    "#                         s = fb.get_score_from_std(std, i)\n",
    "#                     else:\n",
    "#                         raise NotImplementedError\n",
    "#                     s = fb.U_I_minus_B_Ut(s, i)\n",
    "#                     hf = y - fb.W(y, i)\n",
    "#                     dt = - 1.0 / N\n",
    "#                     drift = (s/2 + hf) / dt\n",
    "#                     drift = to_flattened_numpy(drift)\n",
    "#                     return drift\n",
    "#                 x_N = fb.get_x_N([bsize, input_nc, resolution, resolution], N)\n",
    "#                 solution = solve_ivp(ode_func, (1, 1e-3), to_flattened_numpy(x_N),\n",
    "#                                      rtol=1e-3, atol=1e-3, method=\"RK45\")\n",
    "#                 nfe = solution.nfev\n",
    "#                 solution = torch.tensor(solution.y[:, -1]).reshape(x_N.shape).to(device).type(torch.float32)\n",
    "                \n",
    "#                 save_image(solution, \"./solution.jpg\")\n",
    "#                 print(f\"nfe = {nfe}\")\n",
    "#                 raise NotImplementedError\n",
    "#             for x_0, _ in test_loader:\n",
    "#                 x_0 = x_0.to(device)\n",
    "#                 # for v in range(0, 250, 20):\n",
    "#                 #     x_0[:, :, v, :] = 0\n",
    "#                 if opt.fromprior:\n",
    "#                     i = np.array([N - 1] * x_0.shape[0])\n",
    "#                     i = torch.from_numpy(i).to(device)\n",
    "#                     pred = fb.get_x_N(x_0.shape, i)\n",
    "#                     print(f\"pred.std() = {pred.std()}\")\n",
    "#                 else:\n",
    "#                     i = np.array([N-1] * x_0.shape[0])\n",
    "#                     i = torch.from_numpy(i).to(device)\n",
    "#                     pred = fb.get_x_i(x_0, i)\n",
    "#                 preds = [pred]\n",
    "\n",
    "#                 for i in reversed(range(1, N)):\n",
    "#                     i = np.array([i] * x_0.shape[0])\n",
    "#                     i = torch.from_numpy(i).to(device)\n",
    "#                     if opt.gtscore:\n",
    "#                         s = fb.get_score_gt(pred, x_0, i)\n",
    "#                     else:\n",
    "#                         if opt.loss_type == \"sm_simple\":\n",
    "#                             s = model(pred, i)\n",
    "#                         elif opt.loss_type == \"eps_simple\":\n",
    "#                             eps = model(pred, i)\n",
    "#                             s = fb.get_score_from_eps(eps, i)\n",
    "#                         elif opt.loss_type == \"sm_exact\":\n",
    "#                             s = model(pred, i)\n",
    "#                         elif opt.loss_type == \"std_matching\":\n",
    "#                             std = model(pred, i)\n",
    "#                             s = fb.get_score_from_std(std, i)\n",
    "#                         else:\n",
    "#                             raise NotImplementedError\n",
    "#                     s = fb.U_I_minus_B_Ut(s, i)\n",
    "#                     rms = lambda x: torch.sqrt(torch.mean(x ** 2))\n",
    "#                     # print(f\"rms(s) * fb._beta_i(i) = {rms(s) * fb._beta_i(i)[0]}\")\n",
    "#                     hf = pred - fb.W(pred, i)\n",
    "#                     # Anderson theorem\n",
    "#                     pred1 = pred + hf # unsharpening mask filtering\n",
    "#                     pred2 = pred1 + s  # # denoising\n",
    "#                     if i[0] > 2:\n",
    "#                         pred = pred2 + fb.U_I_minus_B_sqrt_Ut(torch.randn_like(pred), i) # inject noise\n",
    "#                     else:\n",
    "#                         pred = pred2\n",
    "#                     # print(f\"i = {i[0]}, rmse = {torch.sqrt(torch.mean(pred**2))}, mean = {torch.mean(pred)} std = {torch.std(pred)}\")\n",
    "#                     # assert rms(pred) < 100\n",
    "#                     if (i[0]) % (N // 10) == 0:\n",
    "#                         img = pred[0]\n",
    "#                         preds.append(pred)\n",
    "\n",
    "#                 preds.append(pred)\n",
    "#                 assert x_0.shape == pred.shape\n",
    "#                 # visualize\n",
    "#                 grid = torch.cat(preds, dim=3) # grid_sample.shape: (bsize, channel, H, W * 12)\n",
    "#                 # (batch_size, channel, H, W * 12) -> (channel, H * bsize, W * 12)\n",
    "#                 grid = grid.permute(1, 0, 2, 3).contiguous().view(grid.shape[1], -1, grid.shape[3])\n",
    "#                 # (bsize, channel, H, W) -> (channel, H, W * bsize)\n",
    "#                 gt = x_0.permute(1, 2, 0, 3).contiguous().view(x_0.shape[1], -1, x_0.shape[3] * x_0.shape[0])\n",
    "#                 if cnt <= 2:\n",
    "#                     utils.tensor_imsave(gt, \"./\" + dir, f\"{step}_{cnt}_GT.jpg\")\n",
    "#                     utils.tensor_imsave(grid, \"./\" + dir, f\"{step}_{cnt}_pred.jpg\")\n",
    "              \n",
    "#                 cnt += 1\n",
    "#                 loss += TF.l1_loss(x_0, pred) / 2\n",
    "\n",
    "#                 if cnt == 2:\n",
    "#                     break\n",
    "#         print(f\"step: {step} loss: {loss}\")\n",
    "#         writer.add_scalar('loss_val', loss, meta_iter)\n",
    "#         f = open('./' + str(dir) + '/log.txt', 'a')\n",
    "\n",
    "#         f.write(f\"Step: {step} loss: {loss}\" + '\\n')\n",
    "\n",
    "#         f.close()\n",
    "#         model.train()\n",
    "#         if opt.use_ema:\n",
    "#             optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "#     if step % opt.save_every == 1:\n",
    "#         if opt.use_ema:\n",
    "#             optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "#         if torch.cuda.device_count() > 1:\n",
    "#             torch.save(model.module.state_dict(), os.path.join(dir, f\"model_{step}.ckpt\"))\n",
    "#         else:\n",
    "#             torch.save(model.state_dict(), os.path.join(dir, f\"model_{step}.ckpt\"))\n",
    "#         if opt.use_ema:\n",
    "#             optimizer.swap_parameters_with_ema(store_params_in_ema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa70436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3a1982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
